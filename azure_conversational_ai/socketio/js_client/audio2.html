<!DOCTYPE html>
<html>
<head>
  <title>Text Input and Display</title>
  <style>
    body {
      background-color: #121212; /* Dark background */
      color: #f0f0f0;            /* Light text for contrast */
      font-family: Arial, sans-serif;
      padding: 20px;
    }

    input[type="text"] {
      background-color: #1e1e1e;
      color: #ffffff;
      border: 1px solid #444;
      padding: 8px;
      width: 300px;
    }

    button {
      background-color: #333;
      color: #fff;
      border: none;
      padding: 8px 16px;
      margin-left: 10px;
      cursor: pointer;
    }

    button:hover {
      background-color: #555;
    }

    #printArea {
      border: 1px solid #444;
      padding: 10px;
      min-height: 20px;
      background-color: #1e1e1e;
      margin-top: 10px;
    }
  </style>
</head>
<body>

  <button id="transcribeButton" onclick="startTranscription()">Start Recording</button>
  <button id="stopButton" onclick="stopTranscription()">Stop Recording</button>

  <script src="https://cdn.socket.io/4.0.0/socket.io.min.js"></script>
  <script>
    const socket = io("http://localhost:5000"); // Connect to your socket.io server
    let isRecording = false;

    socket.on('interim_transcription', (data) => {
            console.log('Received interim transcription:', data.text);
        });


    function startTranscription() {
            if (isRecording) return;
            
            const transcribeButton = document.getElementById('transcribeButton');
            const stopButton = document.getElementById('stopButton');
            transcribeButton.disabled = true;
            stopButton.disabled = false;
            transcribeButton.textContent = 'Recording...';

            // Get access to the microphone
            navigator.mediaDevices.getUserMedia({
                audio: {
                    echoCancellation: false,
                    noiseSuppression: false,
                    autoGainControl: false,
                    sampleRate: 16000
                }
            })
            .then(stream => {
                console.log('Microphone access granted');
                // document.getElementById('result').innerHTML += '<div class="debug">Microphone access granted</div>';
                
                // Create audio context at 16kHz for Speech SDK compatibility
                audioContext = new (window.AudioContext || window.webkitAudioContext)({
                    sampleRate: 16000
                });
                
                // Create microphone input source
                microphone = audioContext.createMediaStreamSource(stream);
                
                // Create script processor to get raw PCM data
                const bufferSize = 16384;
                processor = audioContext.createScriptProcessor(bufferSize, 1, 1);
                
                // When audio data is available
                processor.onaudioprocess = function(e) {
                    // Get raw PCM data from input channel
                    const inputData = e.inputBuffer.getChannelData(0);
                    
                    // Convert to 16-bit PCM (since Float32Array needs to be converted to Int16Array)
                    const pcmData = new Int16Array(inputData.length);
                    for (let i = 0; i < inputData.length; i++) {
                        // Convert float (-1.0 to 1.0) to int16 (-32768 to 32767)
                        pcmData[i] = Math.min(1, Math.max(-1, inputData[i])) * 0x7FFF;
                    }
                    
                    // Send the PCM data to the server
                    const base64Data = arrayBufferToBase64(pcmData.buffer);
                    socket.emit('audio', { audio: base64Data });
                };
                
                // Connect the microphone to the processor and the processor to the destination
                microphone.connect(processor);
                processor.connect(audioContext.destination);
                
                isRecording = true;
            })
            .catch(err => {
                console.error('Error accessing microphone:', err);
                // document.getElementById('result').innerHTML += 
                //     `<div class="debug" style="color:red">Microphone error: ${err.message}</div>`;
                transcribeButton.disabled = false;
                stopButton.disabled = true;
                transcribeButton.textContent = 'Start Recording';
            });
        }

        // Helper function to convert ArrayBuffer to Base64
        function arrayBufferToBase64(buffer) {
            const binary = new Uint8Array(buffer);
            const bytes = Array.from(binary).map(byte => String.fromCharCode(byte)).join('');
            return btoa(bytes);
        }

        function stopTranscription() {
            if (!isRecording) return;
            
            const transcribeButton = document.getElementById('transcribeButton');
            const stopButton = document.getElementById('stopButton');
            transcribeButton.disabled = false;
            stopButton.disabled = true;
            transcribeButton.textContent = 'Start Recording';

            console.log('Stopping transcription');
            
            // Stop recording
            if (processor && microphone) {
                microphone.disconnect();
                processor.disconnect();
                
                if (audioContext && audioContext.state !== 'closed') {
                    audioContext.close().then(() => {
                        console.log('Audio context closed');
                    });
                }
            }
            
            isRecording = false;
            socket.emit('stop_transcription');
        }

        // Clean up on page unload
        window.addEventListener('beforeunload', () => {
            stopTranscription();
        });
  </script>

</body>
</html>
